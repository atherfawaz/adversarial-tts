{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tacotron2 - Nvidia",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyCe31m4O-qr"
      },
      "source": [
        "# Preprocessing and notebook setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WqBSSPISG_R"
      },
      "source": [
        "**Cloning the repository**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8Z0Pw4qM6yW",
        "outputId": "620a36e4-9f9f-466f-e6e1-0279c00d524a"
      },
      "source": [
        "!git clone https://github.com/NVIDIA/tacotron2.git\n",
        "%cd tacotron2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tacotron2'...\n",
            "remote: Enumerating objects: 406, done.\u001b[K\n",
            "remote: Total 406 (delta 0), reused 0 (delta 0), pack-reused 406\u001b[K\n",
            "Receiving objects: 100% (406/406), 2.69 MiB | 32.46 MiB/s, done.\n",
            "Resolving deltas: 100% (205/205), done.\n",
            "/content/tacotron2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoWi2wdHOJcH"
      },
      "source": [
        "**Downloading and extracting the LJSpeech dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Re3PTLpOH-w",
        "outputId": "2c95c170-d31f-47fb-92a0-548ece1a4496"
      },
      "source": [
        "!wget https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
        "!mkdir /content/tacotron2/ljspeech\n",
        "!tar -xf /content/tacotron2/LJSpeech-1.1.tar.bz2 -C /content/tacotron2/ljspeech"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-07 08:35:50--  https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
            "Resolving data.keithito.com (data.keithito.com)... 174.138.79.61\n",
            "Connecting to data.keithito.com (data.keithito.com)|174.138.79.61|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2748572632 (2.6G) [application/octet-stream]\n",
            "Saving to: ‘LJSpeech-1.1.tar.bz2’\n",
            "\n",
            "LJSpeech-1.1.tar.bz 100%[===================>]   2.56G  37.0MB/s    in 38s     \n",
            "\n",
            "2020-12-07 08:36:28 (69.3 MB/s) - ‘LJSpeech-1.1.tar.bz2’ saved [2748572632/2748572632]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP5kkNMZPDrf"
      },
      "source": [
        "**Installing requirements and downgrading to Tensorflow 1.x**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wL5RHOX2Nwsm",
        "outputId": "2415bde6-7221-463c-e3b7-51e7f39010c5"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install unidecode"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 11.8MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pb1gju7VuLg"
      },
      "source": [
        "**Importing the required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVjYqgC8Ncyq"
      },
      "source": [
        "import matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import IPython.display as ipd\n",
        "\n",
        "import sys\n",
        "sys.path.append('waveglow/')\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from hparams import create_hparams\n",
        "from model import Tacotron2\n",
        "from layers import TacotronSTFT, STFT\n",
        "from audio_processing import griffin_lim\n",
        "from train import load_model\n",
        "from text import text_to_sequence"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-7RIyOkV0zx"
      },
      "source": [
        "# Downloading and setting up model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haruXrQ0ULNr"
      },
      "source": [
        "**Setting up plotting prerequisites**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmmchbtJNsVU"
      },
      "source": [
        "def plot_data(data, figsize=(16, 4)):\n",
        "    fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
        "    for i in range(len(data)):\n",
        "        axes[i].imshow(data[i], aspect='auto', origin='bottom', \n",
        "                       interpolation='none')\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTmbSsVgUJC8"
      },
      "source": [
        "**Setting up hparams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFtQlsVIT8w5",
        "outputId": "ad108d86-bcf8-4ce0-aba8-c12df6ca5f0d"
      },
      "source": [
        "hparams = create_hparams()\n",
        "hparams.sampling_rate = 22050"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUO6DNH1UC96"
      },
      "source": [
        "**Downloading the checkpoints of Tacotron2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp_AifOBUILI",
        "outputId": "a415599c-24c2-44aa-fedc-83ef7a77cc0d"
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "print('Downloading tacotron2 model from [https://drive.google.com/file/d/1c5ZTuT7J08wLUoVZ2KkUs_VdZuJ86ZqA/view]')\n",
        "file_id = '1c5ZTuT7J08wLUoVZ2KkUs_VdZuJ86ZqA'\n",
        "destination = '/content/tacotron2/tacotron2_statedict.pt'\n",
        "download_file_from_google_drive(file_id, destination)\n",
        "print('Model downloaded and saved in: ', destination)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading tacotron2 model from [https://drive.google.com/file/d/1c5ZTuT7J08wLUoVZ2KkUs_VdZuJ86ZqA/view]\n",
            "Model downloaded and saved in:  /content/tacotron2/tacotron2_statedict.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNGugWolZGSW"
      },
      "source": [
        "**Loading the checkpoints and the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83UNJYDxT_l3"
      },
      "source": [
        "checkpoint_path = \"/content/tacotron2/tacotron2_statedict.pt\"\n",
        "model = load_model(hparams)\n",
        "model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
        "_ = model.cuda().eval().half()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Recr45Vea8VL"
      },
      "source": [
        "# Inference using Tacotron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrBbxs41Vidn"
      },
      "source": [
        "text = \"I don't like our data science project.\"\n",
        "sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n",
        "sequence = torch.autograd.Variable(torch.from_numpy(sequence)).cuda().long()\n",
        "\n",
        "mel_outputs, mel_outputs_postnet, some_ret_val, alignments = model.inference(sequence)\n",
        "plot_data((mel_outputs.float().data.cpu().numpy()[0],\n",
        "           mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
        "           alignments.float().data.cpu().numpy()[0].T))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmJJDMDWaqd9"
      },
      "source": [
        "**Displaying results of generated data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVH4YrrSXsGK",
        "outputId": "a2d16478-e529-436d-e422-5aed133720f8"
      },
      "source": [
        "print('Sequence: ')\n",
        "print(sequence)\n",
        "print('------')\n",
        "print('Mel-outputs: ')\n",
        "print(mel_outputs)\n",
        "print('------')\n",
        "print('mel_outputs_postnet: ')\n",
        "print(mel_outputs_postnet)\n",
        "print('------')\n",
        "#print('some_ret_val:')\n",
        "#print(some_ret_val)\n",
        "#print('------')\n",
        "print('algnments: ')\n",
        "print(alignments)\n",
        "print('------')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence: \n",
            "tensor([[46, 11, 41, 52, 51,  3, 57, 11, 49, 46, 48, 42, 11, 52, 58, 55, 11, 41,\n",
            "         38, 57, 38, 11, 56, 40, 46, 42, 51, 40, 42, 11, 53, 55, 52, 47, 42, 40,\n",
            "         57,  7]], device='cuda:0')\n",
            "------\n",
            "Mel-outputs: \n",
            "tensor([[[-7.7969, -7.0508, -6.5000,  ..., -9.0391, -8.7578, -8.1875],\n",
            "         [-7.2734, -6.5625, -5.8203,  ..., -7.7617, -7.6406, -7.3672],\n",
            "         [-6.7617, -5.7969, -4.7812,  ..., -6.6367, -6.6680, -6.7500],\n",
            "         ...,\n",
            "         [-9.9062, -9.7109, -9.4062,  ..., -9.4922, -9.5703, -9.6016],\n",
            "         [-9.7891, -9.3984, -9.0703,  ..., -9.4922, -9.5781, -9.6172],\n",
            "         [-9.7109, -9.1406, -8.6328,  ..., -9.5312, -9.6016, -9.6484]]],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<TransposeBackward0>)\n",
            "------\n",
            "mel_outputs_postnet: \n",
            "tensor([[[-7.7617, -7.0469, -6.5078,  ..., -9.1016, -8.7891, -8.1562],\n",
            "         [-7.2461, -6.5508, -5.8164,  ..., -7.8164, -7.6641, -7.3438],\n",
            "         [-6.7422, -5.7930, -4.7773,  ..., -6.6914, -6.6953, -6.7227],\n",
            "         ...,\n",
            "         [-9.9609, -9.8125, -9.6641,  ..., -9.4922, -9.5859, -9.5625],\n",
            "         [-9.8828, -9.5781, -9.3516,  ..., -9.4922, -9.5859, -9.5781],\n",
            "         [-9.8359, -9.3438, -8.8672,  ..., -9.5234, -9.6016, -9.6094]]],\n",
            "       device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)\n",
            "------\n",
            "algnments: \n",
            "tensor([[[6.7041e-01, 1.3375e-04, 2.5153e-04,  ..., 4.4346e-04,\n",
            "          3.1352e-04, 2.7954e-01],\n",
            "         [8.0127e-01, 1.9779e-03, 9.4843e-04,  ..., 2.5177e-03,\n",
            "          1.6851e-03, 1.0107e-01],\n",
            "         [9.5605e-01, 5.9242e-03, 8.2159e-04,  ..., 1.4019e-04,\n",
            "          8.9228e-05, 8.7357e-03],\n",
            "         ...,\n",
            "         [1.8702e-03, 1.2082e-04, 3.8958e-04,  ..., 7.6199e-04,\n",
            "          3.4424e-02, 8.2617e-01],\n",
            "         [1.4153e-03, 6.7890e-05, 3.1376e-04,  ..., 4.1008e-04,\n",
            "          2.3499e-02, 8.6182e-01],\n",
            "         [1.3456e-03, 4.3213e-05, 2.5201e-04,  ..., 2.4271e-04,\n",
            "          1.1940e-02, 9.1113e-01]]], device='cuda:0', dtype=torch.float16,\n",
            "       grad_fn=<TransposeBackward0>)\n",
            "------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}